<!DOCTYPE html>
<html lang="en">

<head>
    <title>High Quality Voice Cloning Audio Samples</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Crimson+Text:400,400i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="index.css">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

    <div class='section'>
        <h1>Sabda2Baachan</h1>
        <!-- <p>Audio samples accompanying the paper</p> -->
        <h2>Abstract</h2>
        <p>This work proposes a novel neural architecture
            Sabda2Baachan for text-to-speech synthesis capable of producing
            high-quality speech with natural prosody and speaker characteris-
            tics. The model employs a multi-stream approach, where distinct
            components predict various low-level prosodic features, including
            energy, pitch, and duration. The
            proposed model demonstrated superior performance compared to
            several state-of-the-art models, achieving remarkable naturalness, in-
            telligibility, and speaker similarity in the synthesized speech</p>
        <h4>Evaluation Metrics:</h4>
        <p>
        <ul class='toc'>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/perceptual_evaluation_speech_quality.html' target="_blank">PERCEPTUAL EVALUATION OF SPEECH QUALITY (PESQ)</a></li>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/signal_distortion_ratio.html' target="_blank">SIGNAL TO DISTORTION RATIO (SDR)</a></li>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/signal_noise_ratio.html' target="_blank">SIGNAL-TO-NOISE RATIO (SNR)</a></li>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/short_time_objective_intelligibility.html' target="_blank">SHORT-TIME OBJECTIVE INTELLIGIBILITY (STOI)</a></li>
        </ul>
        </p>

    </div>

    <hr>
<div class='section table-responsive-sm'>
    <table class="table">
    <h2>Evaluation Metrics  for Different Datasets Split For Sabda2Baachan</h2>
    <thead>
        <tr>
            <th>Splits</th>
            <th>PESQ(nb)</th>
            <th>PESQ(wb)</th>
            <th>SDR</th>
            <th>SNR</th>
            <th>STOI</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Training</td>
            <td>3.024</td>
            <td>2.823</td>
            <td>5.637</td>
            <td>6.179</td>
            <td>0.823</td>
        </tr>
        <tr>
            <td>Validation</td>
            <td>2.535</td>
            <td>2.331</td>
            <td>5.527</td>
            <td>5.137</td>
            <td>0.797</td>
        </tr>
        <tr>
            <td>Testing</td>
            <td>2.277</td>
            <td>2.004</td>
            <td>5.662</td>
            <td>5.029</td>
            <td>0.635</td>
        </tr>
    </tbody>
</table>
</div>

    <hr>

    <div id='section-4' class='section'>
        <h2>Text-to-Speech with Different SOTA Models</h2>

        <h3>Samples</h3>
        <p>The first audio clip for each text is taken from the dataset and the remaining 3 are samples generated by the different models.</p>

        <p class='playlist-title text'>&ldquo;It's about thirty percentage for that reason, your final project is like your first semester first year come to my office, talk to me to&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide18_0040-0050.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sabda2Baachan</p><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide18_0040-0050.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Tortoise</p><audio preload='metadata' controls><source src='audio/tortoise/clip_slide18_0040-0050.mp3.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Bark.</p><audio preload='metadata' controls><source src='audio/Bark/clip_slide18_0040-0050.wav' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>Users. For example, personalized news, the mailing filtering, for example, sometimes you have some app.&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide46_0060-0070.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide46_0060-0070.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/tortoise/clip_slide46_0060-0070.mp3.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Bark/clip_slide46_0060-0070.wav' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>&ldquo;Another trend is about why machine learning models are so popular. Right? Because, there are so many places that we needed to use &rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide56_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide56_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/tortoise/clip_slide56_0000-0010.mp3.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Bark/clip_slide56_0000-0010.wav' type='audio/mpeg'></audio></div>
        </div>
        
        <p class='playlist-title text'>&ldquo;We only utilize a kind of traditional machine learning models. For example, I like the decision tree, the SVM, the KAN, The MLP&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide65_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide65_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/tortoise/clip_slide65_0010-0020.mp3.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Bark/clip_slide65_0010-0020.wav' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>&ldquo;Material handling, some like packaging, machine loading, all kinds of different robotics. They have some machine learning algorithm inside for&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide77_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide77_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/tortoise/clip_slide77_0010-0020.mp3.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Bark/clip_slide77_0010-0020.wav' type='audio/mpeg'></audio></div>
        </div>



        <h3>Text-to-Speech with Different Custom Models within Group Members</h3>
        <p>The first audio clip for each text is taken from the dataset and the remaining 3 are samples generated by the different models.</p>

        <p class='playlist-title text'>&ldquo;Especially the amount that data labeling is a big challenge for all existing machine learning. For those, you definitely need to provide feed&rdquo;</p>
        <div class='playlist five-playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide29_0100-0110.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide29_0100-0110.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='audio/harsa/slide29_0100-0110.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide29_0100_0110.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-0/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>Label the input data. So then one features and labels, professor, feature and labels cn, that's yes. Exactly&rdquo;</p>
        <div class='playlist five-playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide30_0060-0070.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide30_0060-0070-aaayush.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='audio/harsa/slide30_0060-0070.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide30_0060_0070.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-3/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>&ldquo;About two years ago in the two thousand tens. In that, stage, and like, deep learning is rarely and becomes popular. Right?&rdquo;</p>
        <div class='playlist five-playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide34_0030-0040.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide34_0030-0040.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='audio/harsa/slide34_0030-0040.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide34_0030_0040.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-3/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>
        

        <p class='playlist-title text'>&ldquo;Another trend is about why machine learning models are so popular. Right? Because, there are so many places that we needed to use machine learning&rdquo;</p>
        <div class='playlist five-playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide56_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide56_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='audio/harsa/slide56_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide56_0000_0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>
        <p class='playlist-title text'>&ldquo;Your eyes, where is your nose? Where is your mouse? Right? It's funny areas. Right? It's really about personal identification&rdquo;</p>
        <div class='playlist five-playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide69_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide69_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='audio/harsa/slide69_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide69_0010_0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>
    </div>

    <hr>


    <hr>




</body>
</html>

<script>    
document
    .getElementById('select-speaker')   
    .addEventListener('change', function () {
        'use strict';
        var targets = document.getElementsByClassName("select-speaker")
        for (let i = 0; i < targets.length; i++) {
            name = "samples/mp3/ted_speakers/" + this.value + "/sample-" + i.toString() + ".mp3"
            targets[i].setAttribute("src", name)
            targets[i].parentElement.load()
        }
});
</script>
